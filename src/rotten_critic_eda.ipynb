{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3353e561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "import datasets as ds\n",
    "import math\n",
    "import utils as ut\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43f4416",
   "metadata": {},
   "source": [
    "### 1. Carga de información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74e0572a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'datasets' has no attribute 'get_dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m critics_df = \u001b[43mds\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_dataset\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33m../data/raw/rotten_tomatoes_critic_reviews.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m critics_df.head()\n",
      "\u001b[31mAttributeError\u001b[39m: module 'datasets' has no attribute 'get_dataset'"
     ]
    }
   ],
   "source": [
    "critics_df = ds.get_dataset(\"../data/raw/rotten_tomatoes_critic_reviews.csv\")\n",
    "\n",
    "critics_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7c9144",
   "metadata": {},
   "source": [
    "* `rotten_tomatoes_link`: Sirve como identificador de la película\n",
    "* `critic_name`: Nombre del critico que comento la película\n",
    "* `top_critic`: Valor booleano que aclara si el crítico es un crítico destacado o no\n",
    "* `publisher_name`: nombre de la editorial para la que trabaja el crítico\n",
    "* `review_type`: Determina si la reseña es positiva (fresh) o negativa (rotten)\n",
    "* `review_score`: Puntaje proporcionado por el crítico\n",
    "* `review_date`: Fecha de la reseña\n",
    "* `review_content`: Contenido de la reseña"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8c28a8",
   "metadata": {},
   "source": [
    "### 2. Exploración y limpieza\n",
    "\n",
    "**2.1. Comprensión de datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaae6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'El dataframe contiene {critics_df.shape[0]} filas y {critics_df.shape[1]} columnas.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086667d4",
   "metadata": {},
   "source": [
    "**2.2. Identificando nulos y duplicados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f8b221",
   "metadata": {},
   "outputs": [],
   "source": [
    "critics_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65b5894",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(critics_df.isnull().sum())\n",
    "\n",
    "print(\"Duplicados:\", critics_df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4becd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "critics_df = critics_df.drop_duplicates()\n",
    "critics_df = critics_df.dropna(subset=['review_content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576cab0d",
   "metadata": {},
   "source": [
    "* los nulis en el nombre del critico se contrastan con el de publisher name asi que no es grave y se piede mantener\n",
    "* el de review score se compensa con  el de review type ya que determina si es util o no\n",
    "* El de texto si es necesario arreglarlo para cuando se haga el NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb7523c",
   "metadata": {},
   "source": [
    "**2.3. Eliminando información irrelevante**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d8b848",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_cleaned = critics_df.copy().drop(columns=['review_date', 'review_score', 'critic_name'])\n",
    "\n",
    "cr_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d64ece",
   "metadata": {},
   "source": [
    "* La fecha no es relevante para el estudio\n",
    "* El puntaje tiene sus nulos, además de que ya hay un boolean que dice si la reseña sera positiva o negativa\n",
    "* El nombre del critico no hace falta si ya esta el de la editorial que lo publica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339c4dcb",
   "metadata": {},
   "source": [
    "### 3. Análisis univariante\n",
    "**3.1. Dividir el Dataset en categoricos y numericos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c4b172",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_df_copy = cr_cleaned.copy()\n",
    "c_df_copy.dtypes.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f756724c",
   "metadata": {},
   "source": [
    "* Todas son categoricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baeeb775",
   "metadata": {},
   "source": [
    "**3.2. Análisis sober variables categóricas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abb8b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c_df_copy['rotten_tomatoes_link'].value_counts().head(10))\n",
    "print(f\"Total de productos únicos: {c_df_copy['rotten_tomatoes_link'].nunique()}\")\n",
    "print(\"------------------------------------------------------\")\n",
    "print(c_df_copy['publisher_name'].value_counts().head(10))\n",
    "print(f\"Total de editoriales únicos: {c_df_copy['publisher_name'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a184583",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [ 'top_critic', 'review_type']\n",
    "\n",
    "\n",
    "for col in categorical_cols:\n",
    "    c_df_copy[col].value_counts().plot(kind='bar', figsize=(6,4), title=col)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf524118",
   "metadata": {},
   "source": [
    "* La mayoría de críticos no son destacados en una proporción casi dos veces mas que los que si lo son\n",
    "* Las reseñas positivas son casi el doble a las de negativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3896bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_peliculas = 10\n",
    "top_n_editorial = 10\n",
    "\n",
    "fig, axis = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# PRODUCTOS\n",
    "top_products = c_df_copy['rotten_tomatoes_link'].value_counts().head(top_n_peliculas).index\n",
    "sns.countplot(ax=axis[0], data=c_df_copy, x='rotten_tomatoes_link', order=top_products)\n",
    "axis[0].set_title(\"Top 10 Peliculas reseñadas\")\n",
    "axis[0].tick_params(axis='x', rotation=90)\n",
    "print(\"Top 10 peliculas graficados:\", len(top_products))\n",
    "\n",
    "# USUARIOS\n",
    "top_users = c_df_copy['publisher_name'].value_counts().head(top_n_editorial).index\n",
    "sns.countplot(ax=axis[1], data=c_df_copy, x='publisher_name', order=top_users)\n",
    "axis[1].set_title(\"Top 10 Editoriales\")\n",
    "axis[1].tick_params(axis='x', rotation=45)\n",
    "print(\"Top 10 editoriales graficados:\", len(top_users))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2f2511",
   "metadata": {},
   "source": [
    "* El top de peliculas reseñadas esta rodeando las 500 reseñas\n",
    "* La editorial con mas reseñas de películas es New York Times con casi 12000, avanzando de manera descendente hasta Chicado Sun-Times con casi 8000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9fed07",
   "metadata": {},
   "source": [
    "### 4. Análisis multivariante\n",
    "**4.3. Categorico-Categorico Análisis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f312c6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_cat(df, cat1, cat2, top_n_cat1=None, top_n_cat2=None):\n",
    "    \n",
    "    if top_n_cat1:\n",
    "        top_values1 = df[cat1].value_counts().nlargest(top_n_cat1).index\n",
    "        df = df[df[cat1].isin(top_values1)]\n",
    "    if top_n_cat2:\n",
    "        top_values2 = df[cat2].value_counts().nlargest(top_n_cat2).index\n",
    "        df = df[df[cat2].isin(top_values2)]\n",
    "    \n",
    "    ct = pd.crosstab(df[cat1], df[cat2])\n",
    "    \n",
    "    ct_prop = ct.div(ct.sum(axis=1).replace(0,1), axis=0)\n",
    "    \n",
    "    ct_prop.plot(kind='bar', stacked=True, figsize=(12,6))\n",
    "    plt.xlabel(cat1)\n",
    "    plt.ylabel('Proporción')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.legend(title=cat2, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b24f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cat(c_df_copy, 'rotten_tomatoes_link', 'publisher_name', top_n_cat1=top_n_peliculas, top_n_cat2=top_n_editorial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b66688",
   "metadata": {},
   "source": [
    "* Parece que eFilmCritic.com es quien mas reseñas hace a las peliculas con mas reseñas del top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dac1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cat(c_df_copy, 'top_critic', 'publisher_name', top_n_cat2=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c7761f",
   "metadata": {},
   "source": [
    "* Se ve que la mayoría de las editoriales con mas reseñas tienen criticos cuya opinion es validada, es imporatnte teniendo en cuenta que hay mas con la categoría false que con la de true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab5b631",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cat(c_df_copy, 'review_type', 'rotten_tomatoes_link', top_n_cat2=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7a1d38",
   "metadata": {},
   "source": [
    "* Las buenas reseñas estan distribuidas mas equitativamente entre las peliculas mientras que las malas se acumulan, esto demestra que se le da importancia a que hay pelis con mas reseñas malas que buenas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12117d9c",
   "metadata": {},
   "source": [
    "### 5. Ingeniería de características"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca15b5ac",
   "metadata": {},
   "source": [
    "**5.1. Preparar los datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78124b0",
   "metadata": {},
   "source": [
    "* Como primera etapa vamos a mapear las reseñas de frescas o podridas como boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c108d5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_df_copy['review_label'] = c_df_copy['review_type'].map({'Fresh': 1, 'Rotten': 0})\n",
    "\n",
    "print(c_df_copy[['review_type', 'review_label']].head())\n",
    "c_df_copy.drop(columns=['review_type'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735bbd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b44dc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_df_copy['top_critic_num'] = c_df_copy['top_critic'].astype(int)\n",
    "c_df_copy.drop(columns=['top_critic'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3428b07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_df_copy['review_len'] = c_df_copy['review_content'].str.len()\n",
    "\n",
    "# cantidad de palabras\n",
    "c_df_copy['review_word_count'] = c_df_copy['review_content'].str.split().apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e4d7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_df_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1971d3ff",
   "metadata": {},
   "source": [
    "**5.2. Análisis de outliers**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d41dbd",
   "metadata": {},
   "source": [
    "* Para la longitud de reseñas se tendra en cuenta que tenga un minimo de longitud para que eralmente cuente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf66ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_df_copy = c_df_copy[(c_df_copy['review_len'] >= 10) & (c_df_copy['review_len'] <= 5000)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e34b4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['review_len', 'review_word_count', 'top_critic_num', 'review_label']\n",
    "\n",
    "for col in num_cols:\n",
    "    plt.figure(figsize=(8,2))\n",
    "    sns.boxplot(x=c_df_copy[col])\n",
    "    plt.title(f'Boxplot de {col}')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eca5bb",
   "metadata": {},
   "source": [
    "**5.2. Dividir el train/test de marcos de datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edab54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = c_df_copy['review_content']  \n",
    "y = c_df_copy['review_label']    \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723488ef",
   "metadata": {},
   "source": [
    "### 6. Transformar el texto en matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabe7bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_model = CountVectorizer(stop_words = \"english\", max_features=5000)\n",
    "X_train_vec = vec_model.fit_transform(X_train)\n",
    "X_test_vec = vec_model.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede0856a",
   "metadata": {},
   "source": [
    "### 7. Contruir el naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7714ed55",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_vec, y_train)\n",
    "\n",
    "y_pred_nb = nb_model.predict(X_test_vec)\n",
    "print(\"Naive Bayes Accuracy:\", accuracy_score(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5276f9eb",
   "metadata": {},
   "source": [
    "### 8. Optimización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7933fc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_modelo(model, X_train_vec, X_test_vec, y_train, y_test, nombre=\"Modelo\"):\n",
    "    model.fit(X_train_vec, y_train)\n",
    "    y_pred = model.predict(X_test_vec)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{nombre} Accuracy: {acc:.5f}\")\n",
    "    return model, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ed36d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(stop_words='english')),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "hyperparams = {\n",
    "    'vectorizer__max_features': [1000, 2000, 3000, None],\n",
    "    'vectorizer__ngram_range': [(1,1), (1,2)],\n",
    "    'nb__alpha': np.linspace(0.1, 2.0, 20)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3743c85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes simple\n",
    "vec_model = CountVectorizer(stop_words=\"english\")\n",
    "X_train_vec = vec_model.fit_transform(X_train)\n",
    "X_test_vec  = vec_model.transform(X_test)\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "nb_model, y_pred_nb = evaluar_modelo(nb_model, X_train_vec, X_test_vec, y_train, y_test, \"Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffac4f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Naive Bayes optimizado con Pipeline + RandomizedSearchCV\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(stop_words='english')),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "hyperparams = {\n",
    "    'vectorizer__max_features': [1000, 2000, 3000, None],\n",
    "    'vectorizer__ngram_range': [(1,1), (1,2)],\n",
    "    'nb__alpha': np.linspace(0.1, 2.0, 20)\n",
    "}\n",
    "\n",
    "grid = RandomizedSearchCV(pipeline, hyperparams, scoring=\"accuracy\", n_iter=20, random_state=42)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_nb_model = grid.best_estimator_\n",
    "y_pred_best_nb = best_nb_model.predict(X_test)\n",
    "\n",
    "print(\"Naive Bayes Optimizado Accuracy:\", accuracy_score(y_test, y_pred_best_nb))\n",
    "print(\"Mejores parámetros:\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653a2d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "log_model = LogisticRegression(max_iter=1000)\n",
    "log_model, y_pred_log = evaluar_modelo(log_model, X_train_vec, X_test_vec, y_train, y_test, \"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1aca6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_nb = accuracy_score(y_test, y_pred_best_nb)\n",
    "acc_log = accuracy_score(y_test, y_pred_log)\n",
    "\n",
    "if acc_log > acc_nb:\n",
    "    modelo_final = log_model\n",
    "    nombre_final = \"Logistic Regression\"\n",
    "else:\n",
    "    modelo_final = best_nb_model\n",
    "    nombre_final = \"Naive Bayes Optimizado\"\n",
    "\n",
    "print(f\"Mejor modelo: {nombre_final} ({max(acc_nb, acc_log):.5f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfefc4b6",
   "metadata": {},
   "source": [
    "### 9. Guardar Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c185c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"vectorizer\", CountVectorizer(stop_words=\"english\")),\n",
    "    (\"classifier\", modelo_final)   \n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Guardar el pipeline completo\n",
    "with open(\"../models/rotten_pipeline.pkl\", \"wb\") as f:\n",
    "    pickle.dump(pipeline, f)\n",
    "\n",
    "print(\"Pipeline con modelo final guardado correctamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9f0a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_pipeline = \"../models/rotten_pipeline.pkl\"\n",
    "with open(ruta_pipeline, \"rb\") as f:\n",
    "    pipeline_cargado = pickle.load(f)\n",
    "\n",
    "pruebas = [\n",
    "    \"The movie was amazing, I loved every minute of it!\",\n",
    "    \"Absolutely terrible. I wasted two hours of my life.\",\n",
    "    \"It was okay, some parts were good but others were boring.\",\n",
    "    \"A masterpiece of cinematography and storytelling.\",\n",
    "    \"Horrible acting and a very weak plot.\",\n",
    "]\n",
    "\n",
    "\n",
    "predicciones = pipeline_cargado.predict(pruebas)\n",
    "\n",
    "for review, pred in zip(pruebas, predicciones):\n",
    "    etiqueta = \"Positive\" if pred == 1 else \"Negative\"\n",
    "    print(f\"Review: {review}\\nPredicted sentiment: {etiqueta}\\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

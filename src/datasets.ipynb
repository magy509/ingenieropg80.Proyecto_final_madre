{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c0984c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import utils as eda\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d648e75a",
   "metadata": {},
   "source": [
    "## Datasets de peliculas y datos de reseñas y etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dcb3645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['README.txt', 'checksums.txt', 'tags.csv', 'movies.csv', 'links.csv', 'ratings.csv']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(os.listdir(\"../data/interim/movies-data/ml-32m\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efed7c99",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mParserError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m df_list = []\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m informacion:\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../data/interim/movies-data/ml-32m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     df_list.append(df)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:626\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1923\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1916\u001b[39m nrows = validate_integer(\u001b[33m\"\u001b[39m\u001b[33mnrows\u001b[39m\u001b[33m\"\u001b[39m, nrows)\n\u001b[32m   1917\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1918\u001b[39m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[32m   1919\u001b[39m     (\n\u001b[32m   1920\u001b[39m         index,\n\u001b[32m   1921\u001b[39m         columns,\n\u001b[32m   1922\u001b[39m         col_dict,\n\u001b[32m-> \u001b[39m\u001b[32m1923\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[32m   1924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[32m   1925\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1927\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[39m, in \u001b[36mCParserWrapper.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.low_memory:\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m         chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[32m    236\u001b[39m         data = _concatenate_chunks(chunks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:838\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.read_low_memory\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:905\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._read_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:874\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:891\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:2061\u001b[39m, in \u001b[36mpandas._libs.parsers.raise_parser_error\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mParserError\u001b[39m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mEl kernel se bloqueó al ejecutar código en la celda actual o en una celda anterior. \n",
      "\u001b[1;31mRevise el código de las celdas para identificar una posible causa del error. \n",
      "\u001b[1;31mHaga clic <a href='https://aka.ms/vscodeJupyterKernelCrash'>aquí</a> para obtener más información. \n",
      "\u001b[1;31mVea Jupyter <a href='command:jupyter.viewOutput'>log</a> para obtener más detalles."
     ]
    }
   ],
   "source": [
    "\n",
    "informacion = [\"links\", \"movies\", \"ratings\", \"tags\"]\n",
    "df_list = []\n",
    "\n",
    "for i in informacion:\n",
    "    df = pd.read_csv(f\"../data/interim/movies-data/ml-32m/{i}.csv\")\n",
    "    df_list.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c631538",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Links\n",
    "links_df = df_list[0].head()\n",
    "\n",
    "\n",
    "##La siguiente información muestra como funciona la info que sale en el dataset de links\n",
    "\"\"\"row = df_list[df_list[\"movieId\"] == 1].iloc[0]\n",
    "\n",
    "imdb_url = f\"https://www.imdb.com/title/tt{int(row['imdbId']):07d}\"\n",
    "tmdb_url = f\"https://www.themoviedb.org/movie/{int(row['tmdbId'])}\"\n",
    "\n",
    "print(\"IMDb:\", imdb_url)\n",
    "print(\"TMDb:\", tmdb_url\"\"\"\n",
    "\n",
    "links_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1611722c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Movies \n",
    "movies_df = df_list[1]\n",
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f106c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Raiting\n",
    "rating_df =  df_list[2].head()\n",
    "rating_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d997ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tags\n",
    "tags_df = df_list[3].head()\n",
    "tags_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d225a44e",
   "metadata": {},
   "source": [
    "## Información referente a comentarios de sentimientos, estos deben asociarse a peliculas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32988055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_reseñas(directorio):\n",
    "    textos = []\n",
    "    etiquetas = []\n",
    "\n",
    "    for label in ['pos', 'neg']:\n",
    "        path = os.path.join(directorio, label)\n",
    "        for archivo in os.listdir(path):\n",
    "            with open(os.path.join(path, archivo), encoding='utf-8') as f:\n",
    "                textos.append(f.read())\n",
    "                etiquetas.append(1 if label == 'pos' else 0)\n",
    "    return textos, etiquetas\n",
    "\n",
    "# Cargar datos de entrenamiento y prueba\n",
    "train_texts, train_labels = cargar_reseñas(\"../data/interim/feeling/aclImdb/train\") ##texto de reseñas // ETIQUETA para positivo y negativo\n",
    "test_texts, test_labels = cargar_reseñas(\"../data/interim/feeling/aclImdb/test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e9c782",
   "metadata": {},
   "source": [
    "## Otro sitio de peliculas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6c015d",
   "metadata": {},
   "source": [
    "Este servira mas para mostrar datos o complementar los de una pelicula que ya tengamos en el dataset principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c930ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Esta es para varias peliculas\n",
    "api_key = \"fa1b7162\" ##Esto es lo importante, no lo borren ni cambien\n",
    "peliculas = [\"Inception\", \"The Matrix\", \"Toy Story\"]\n",
    "\n",
    "datos_peliculas = []\n",
    "\n",
    "for titulo in peliculas:\n",
    "    url = f\"http://www.omdbapi.com/?t={titulo}&apikey={api_key}\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    if data[\"Response\"] == \"True\":\n",
    "        datos_peliculas.append(data)\n",
    "\n",
    "datos_peliculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73338fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(datos_peliculas, columns=['Title', 'Year', 'Rated', 'Released', 'Runtime', 'Genre', 'Director', 'Writer', 'Actors', 'Plot', 'Language', 'Country', 'Awards', 'Poster', 'Ratings', 'Metascore', 'imdbRating', 'imdbVotes', 'imdbID', 'Type', 'DVD', 'BoxOffice', 'Production', 'Website', 'Response'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8f589e",
   "metadata": {},
   "source": [
    "Combinación de ambas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9426f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d0042b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "movies = df_list[1].head(50)\n",
    "# Función para limpiar título\n",
    "def limpiar_titulo(titulo):\n",
    "    # Esto elimina \" (1995)\" u otros años entre paréntesis\n",
    "    return re.sub(r\"\\s*\\(\\d{4}\\)$\", \"\", titulo)\n",
    "\n",
    "# Aplicar limpieza\n",
    "movies[\"clean_title\"] = movies[\"title\"].apply(limpiar_titulo)\n",
    "\n",
    "# Extraer año si quieres\n",
    "def extraer_ano(titulo):\n",
    "    match = re.search(r\"\\((\\d{4})\\)$\", titulo)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None\n",
    "\n",
    "movies[\"year\"] = movies[\"title\"].apply(extraer_ano)\n",
    "\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e791df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "omdb_url = \"http://www.omdbapi.com/\"\n",
    "\n",
    "# 3️⃣ Función para obtener info de OMDb\n",
    "def obtener_info_omdb(titulo):\n",
    "    params = {\n",
    "        \"t\": titulo,\n",
    "        \"apikey\": api_key,\n",
    "        \"plot\": \"short\",  # puedes poner \"full\" si quieres la sinopsis completa\n",
    "        \"r\": \"json\"\n",
    "    }\n",
    "    response = requests.get(omdb_url, params=params)\n",
    "    data = response.json()\n",
    "    if data.get(\"Response\") == \"True\":\n",
    "        return {\n",
    "            \"Title\": data.get(\"Title\"),\n",
    "            \"Year\": data.get(\"Year\"),\n",
    "            \"Genre\": data.get(\"Genre\"),\n",
    "            \"Director\": data.get(\"Director\"),\n",
    "            \"Actors\": data.get(\"Actors\"),\n",
    "            \"imdbRating\": data.get(\"imdbRating\"),\n",
    "            \"Plot\": data.get(\"Plot\")\n",
    "        }\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# 4️⃣ Consultar OMDb para todas las películas y guardar resultados\n",
    "info_peliculas = []\n",
    "for index, row in movies.iterrows():\n",
    "    titulo = row[\"clean_title\"]\n",
    "    info = obtener_info_omdb(titulo)\n",
    "    if info:\n",
    "        info[\"movieId\"] = row[\"movieId\"]\n",
    "        info_peliculas.append(info)\n",
    "    time.sleep(0.2)  # para no saturar la API (limite de peticiones)\n",
    "\n",
    "# 5️⃣ Crear DataFrame final\n",
    "df_omdb = pd.DataFrame(info_peliculas)\n",
    "##df_omdb.to_csv(\"movies_omdb.csv\", index=False) Esto guarda un csv asi que hay que ver una ruta en caso de que vayamos a usarlo\n",
    "\n",
    "df_omdb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623d5457",
   "metadata": {},
   "source": [
    "## Dataset de Amazon de reseñas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d39012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "\n",
    "file_path = \"../data/interim/movies.txt.gz\"\n",
    "data = []\n",
    "current_review = {}\n",
    "max_reviews = 10000  # cambiar según lo que quieras cargar\n",
    "\n",
    "with gzip.open(file_path, \"rt\", encoding=\"latin-1\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        if line.startswith(\"product/productId:\"):\n",
    "            if current_review:\n",
    "                data.append(current_review)\n",
    "                if len(data) >= max_reviews:\n",
    "                    break  # paramos al llegar al límite\n",
    "                current_review = {}\n",
    "            current_review[\"productId\"] = line[len(\"product/productId: \"):]\n",
    "        elif line.startswith(\"review/userId:\"):\n",
    "            current_review[\"userId\"] = line[len(\"review/userId: \"):]\n",
    "        elif line.startswith(\"review/profileName:\"):\n",
    "            current_review[\"profileName\"] = line[len(\"review/profileName: \"):]\n",
    "        elif line.startswith(\"review/helpfulness:\"):\n",
    "            current_review[\"helpfulness\"] = line[len(\"review/helpfulness: \"):]\n",
    "        elif line.startswith(\"review/score:\"):\n",
    "            try:\n",
    "                current_review[\"score\"] = float(line[len(\"review/score: \"):])\n",
    "            except:\n",
    "                current_review[\"score\"] = None\n",
    "        elif line.startswith(\"review/time:\"):\n",
    "            try:\n",
    "                current_review[\"time\"] = int(line[len(\"review/time: \"):])\n",
    "            except:\n",
    "                current_review[\"time\"] = None\n",
    "        elif line.startswith(\"review/summary:\"):\n",
    "            current_review[\"summary\"] = line[len(\"review/summary: \"):] if len(line) > len(\"review/summary: \") else \"\"\n",
    "        elif line.startswith(\"review/text:\"):\n",
    "            current_review[\"text\"] = line[len(\"review/text: \"):] if len(line) > len(\"review/text: \") else \"\"\n",
    "\n",
    "    if current_review and len(data) < max_reviews:\n",
    "        data.append(current_review)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df.head())\n",
    "print(f\"Se cargaron {len(df)} reseñas\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96bad37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abde7cbe",
   "metadata": {},
   "source": [
    "## Datasets de Reseñas\n",
    "\n",
    "tiene reseñas y se clasifican en sentimiento, pero no estan asociados a peliculas asi que las asignamos aleatoriamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce4f87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = '../data/interim/imdb-dataset/IMDB Dataset SPANISH.csv'\n",
    "\n",
    "df_imdb = pd.read_csv(csv_path)\n",
    "df_imdb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086bbdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Se le asigna un id del dataset de peliculas\n",
    "\n",
    "# Número de reseñas\n",
    "n_reviews = len(df_imdb)\n",
    "\n",
    "# Lista de IDs de películas disponibles\n",
    "movie_ids = movies_df['movieId'].tolist()\n",
    "\n",
    "# Asignar aleatoriamente un movieId a cada reseña\n",
    "df_imdb['movieId'] = np.random.choice(movie_ids, size=n_reviews)\n",
    "\n",
    "# Revisar\n",
    "df_imdb.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
